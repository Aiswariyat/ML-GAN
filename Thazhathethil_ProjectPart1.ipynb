{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6j_snDIjpQQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import time\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "NuHLxppvpQNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.InputLayer(input_shape=(100,)),\n",
        "        layers.Reshape((1, 1, 100)),\n",
        "\n",
        "        layers.Conv2DTranspose(2048, (4, 4), strides=(1, 1), padding='valid', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "\n",
        "        layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "\n",
        "        layers.Conv2DTranspose(512, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "\n",
        "        layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "\n",
        "        layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', input_shape=(128, 128, 3), use_bias=False),\n",
        "        layers.LeakyReLU(0.2),\n",
        "\n",
        "        layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(0.2),\n",
        "\n",
        "        layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(0.2),\n",
        "\n",
        "        layers.Conv2D(1024, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(0.2),\n",
        "\n",
        "        layers.Conv2D(2048, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(0.2),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Create the models\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n"
      ],
      "metadata": {
        "id": "ee5ncF4kpQJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()"
      ],
      "metadata": {
        "id": "iQOzSkDgpQGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "3q30S7ffpQDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss and optimizers\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.999)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.999)"
      ],
      "metadata": {
        "id": "CFxHqAnVpQAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare the dataset\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 500\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "# Directory containing your data\n",
        "data_dir = '/content/drive/MyDrive/ML_Pro1/training/Loc'\n",
        "\n",
        "def load_and_preprocess_data():\n",
        "    # Assuming your directory structure is like: training/center/*.png\n",
        "    data_dir = pathlib.Path(\"/content/drive/MyDrive/ML_Pro1/training/Loc\")\n",
        "    # Count the total images\n",
        "    image_count = len(list(data_dir.glob('*.png')))\n",
        "    print(f\"Total images: {image_count}\")\n",
        "\n",
        "    # Create a dataset from the file paths\n",
        "    list_ds = tf.data.Dataset.list_files(str(data_dir/'*'))\n",
        "\n",
        "    # Define a function to load and preprocess each image\n",
        "    def parse_image(file_path):\n",
        "        # Load the raw data from the file as a string\n",
        "        img = tf.io.read_file(file_path)\n",
        "        # Convert the compressed string to a 3D uint8 tensor\n",
        "        img = tf.image.decode_png(img, channels=3)\n",
        "        # Resize the image to the desired size\n",
        "        img = tf.image.resize(img, [128, 128])\n",
        "        # Normalize the image data to [0, 1] range\n",
        "        img = (img - 127.5) / 127.5\n",
        "        return img\n",
        "\n",
        "    # Use the `map` method to apply this transformation\n",
        "    images_ds = list_ds.map(parse_image)\n",
        "\n",
        "    # Apply the batching\n",
        "    images_ds = images_ds.batch(BATCH_SIZE)\n",
        "\n",
        "    return images_ds"
      ],
      "metadata": {
        "id": "4xWNEtH_pP94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a forward pass with the generator and discriminator to initialize variables\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "decision = discriminator(generated_image)\n",
        "gen_loss_epoch = []\n",
        "disc_loss_epoch = []\n",
        "# Training loop\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        gen_loss_list = []\n",
        "        disc_loss_list = []\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            t_gen_loss, t_disc_loss = train_step(image_batch)\n",
        "            gen_loss_list.append(t_gen_loss)\n",
        "            disc_loss_list.append(t_disc_loss)\n",
        "\n",
        "        # Saving (checkpoint) the model every 50 epochs\n",
        "        if (epoch + 1) % 50 == 0:\n",
        "            generator.save(f'LocGenerator_epoch_{epoch+1}.h5')  # Save the generator model\n",
        "\n",
        "        # Save the losses for this epoch\n",
        "        gen_loss_epoch.append(np.mean(gen_loss_list))\n",
        "        disc_loss_epoch.append(np.mean(disc_loss_list))\n",
        "\n",
        "        print(f'Time for epoch {epoch + 1} is {time.time()-start} sec')\n",
        "\n",
        "    # Save the losses after training\n",
        "    np.save('generator_losses_Loc.npy', gen_loss_epoch)\n",
        "    np.save('discriminator_losses_Loc.npy', disc_loss_epoch)\n"
      ],
      "metadata": {
        "id": "Eol5cRI8pP6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train_dataset = load_and_preprocess_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H8mbyt3pP1x",
        "outputId": "aa7af43b-b008-4a58-d543-6c3db99726d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 1620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRymuMY0pPsG",
        "outputId": "57163f54-cd03-4141-c6a4-0b0b1542d0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "R0BuAh42pinf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the losses\n",
        "generator_losses = np.load('generator_losses_Loc.npy')\n",
        "discriminator_losses = np.load('discriminator_losses_Loc.npy')\n",
        "\n",
        "# Generate x values (epochs)\n",
        "epochs = np.arange(1, len(generator_losses) + 1)\n",
        "\n",
        "# Plot the losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, generator_losses, label='Generator Loss', color='blue')\n",
        "plt.plot(epochs, discriminator_losses, label='Discriminator Loss', color='red')\n",
        "plt.title('Generator and Discriminator Losses for Loc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('LossGraph_Loc.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cweexpvbpik-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#automated image generation\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Define the range of epochs\n",
        "start_epoch = 50\n",
        "end_epoch = 501\n",
        "\n",
        "# Number of images to generate per epoch\n",
        "num_images_per_epoch = 100\n",
        "\n",
        "# Loop over the desired range of epochs\n",
        "for epoch in range(start_epoch,end_epoch, 50):\n",
        "    # Construct the model file name based on the current epoch\n",
        "    model_file = f'/content/drive/MyDrive/ML_Pro1/Loc_Models/LocGenerator_epoch_{epoch}.h5'\n",
        "\n",
        "    # Load the Generator Model\n",
        "    generator = load_model(model_file)  # Replace with your actual path\n",
        "\n",
        "    # Create a directory to save the images for each epoch\n",
        "    epoch_dir = f'/content/drive/MyDrive/ML_Pro1/Loc_data/Loc_{epoch}Epoch_Images'\n",
        "    os.makedirs(epoch_dir, exist_ok=True)\n",
        "\n",
        "    # Inner loop for generating images in each epoch\n",
        "    for i in range(num_images_per_epoch):\n",
        "        # Generate a random input\n",
        "        random_input = np.random.randn(1, 100)  # Assuming 100 is the size of your input vector\n",
        "\n",
        "        # Generate an image\n",
        "        generated_image = generator.predict(random_input)\n",
        "\n",
        "        # Define the file path to save the image\n",
        "        file_path = os.path.join(epoch_dir, f'image_{i}.png')\n",
        "\n",
        "        # Save the generated image to the specified file path\n",
        "        tf.keras.preprocessing.image.save_img(file_path, generated_image[0, :, :, :])\n",
        "\n",
        "    print(f'Generated {num_images_per_epoch} images for epoch {epoch} using {model_file} in {epoch_dir}')"
      ],
      "metadata": {
        "id": "kdj1G2RRpiiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FID and KID"
      ],
      "metadata": {
        "id": "frB-btk00Nfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models import inception_v3\n",
        "from torchvision import transforms\n",
        "from scipy.linalg import sqrtm\n",
        "import numpy as np\n",
        "from torch.nn.functional import adaptive_avg_pool2d\n",
        "from sklearn.metrics import pairwise_kernels\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2):\n",
        "    # Ensure covariance matrices are 2D arrays\n",
        "    sigma1 = np.atleast_2d(sigma1)\n",
        "    sigma2 = np.atleast_2d(sigma2)\n",
        "\n",
        "    # Calculate FID using the formula\n",
        "    fid = np.sum((mu1 - mu2)**2) + np.trace(sigma1 + sigma2 - 2 * sqrtm(sigma1 @ sigma2))\n",
        "    return fid.real\n",
        "\n",
        "def calculate_kernel_distance(features_real, features_generated, kernel='linear'):\n",
        "    # Reshape features to 2D arrays\n",
        "    features_real = np.reshape(features_real, (len(features_real), -1))\n",
        "    features_generated = np.reshape(features_generated, (len(features_generated), -1))\n",
        "\n",
        "    # Calculate KID using the specified kernel\n",
        "    if kernel == 'linear':\n",
        "        return np.mean(pairwise_kernels(features_real, features_generated, metric='linear'))\n",
        "    elif kernel == 'rbf':\n",
        "        return np.mean(pairwise_kernels(features_real, features_generated, metric='rbf'))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported kernel. Supported kernels are 'linear' and 'rbf'.\")\n",
        "\n",
        "def calculate_activation_statistics(features):\n",
        "    # Calculate mean and covariance of the features\n",
        "    mu = np.mean(features, axis=0)\n",
        "    sigma = np.cov(features, rowvar=False)\n",
        "    return mu, sigma\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    # Open the image using PIL\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # Convert to RGB if the image has an alpha channel\n",
        "    if img.mode == 'RGBA':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Preprocess image to match Inception-v3 requirements\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((299, 299)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    img = transform(img)\n",
        "    img = img.unsqueeze(0)  # Add batch dimension\n",
        "    return img\n",
        "\n",
        "def calculate_fid_kid(real_images, generated_images, device='cuda', batch_size=50):\n",
        "    # Load Inception-v3 model\n",
        "    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
        "    inception_model.eval()\n",
        "\n",
        "    # Calculate Inception-v3 features for real images\n",
        "    real_features = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(real_images), batch_size):\n",
        "            batch = real_images[i:i+batch_size].to(device)\n",
        "            features = inception_model(batch)[0].squeeze().cpu().numpy()\n",
        "            real_features.append(features)\n",
        "    real_features = np.concatenate(real_features, axis=0)\n",
        "\n",
        "    # Calculate Inception-v3 features for generated images\n",
        "    generated_features = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(generated_images), batch_size):\n",
        "            batch = generated_images[i:i+batch_size].to(device)\n",
        "            features = inception_model(batch)[0].squeeze().cpu().numpy()\n",
        "            generated_features.append(features)\n",
        "    generated_features = np.concatenate(generated_features, axis=0)\n",
        "\n",
        "    # Calculate FID and KID scores\n",
        "    mu_real, sigma_real = calculate_activation_statistics(real_features)\n",
        "    mu_generated, sigma_generated = calculate_activation_statistics(generated_features)\n",
        "\n",
        "    fid = calculate_frechet_distance(mu_real, sigma_real, mu_generated, sigma_generated)\n",
        "    kid = calculate_kernel_distance(real_features, generated_features)\n",
        "\n",
        "    return fid, kid\n",
        "\n",
        "def load_and_preprocess_images_from_folder(folder):\n",
        "    # Load and preprocess only .png files from the specified folder\n",
        "    file_paths = glob.glob(os.path.join(folder, '*.png'))\n",
        "\n",
        "    images = []\n",
        "    for img_path in file_paths:\n",
        "        try:\n",
        "            img = preprocess_image(img_path)\n",
        "            images.append(img)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {img_path}: {e}\")\n",
        "\n",
        "    if not images:\n",
        "        raise ValueError(\"No valid images found in the folder.\")\n",
        "\n",
        "    return torch.cat(images, dim=0)  # Use torch.cat instead of torch.stack\n",
        "\n",
        "\n",
        "def calculate_fid_kid_for_epochs(real_folder, generated_base_folder, epochs, excel_path='FID_KID_scores_Loc.csv'):\n",
        "    # Check if the Excel file already exists\n",
        "    if os.path.exists(excel_path):\n",
        "        # If it exists, read the existing data\n",
        "        df = pd.read_csv(excel_path)\n",
        "    else:\n",
        "        # If it doesn't exist, create an empty DataFrame\n",
        "        df = pd.DataFrame(columns=['Epoch', 'FID', 'KID'])\n",
        "\n",
        "    # Iterate over each epoch\n",
        "    for epoch in epochs:\n",
        "        epoch_folder_name = f'Loc_{epoch}Epoch_Images'\n",
        "        generated_images_folder = os.path.join(generated_base_folder, epoch_folder_name)\n",
        "\n",
        "        # Load real images\n",
        "        real_images = load_and_preprocess_images_from_folder(real_folder)\n",
        "\n",
        "        # Load generated images for the current epoch\n",
        "        try:\n",
        "            generated_images = load_and_preprocess_images_from_folder(generated_images_folder)\n",
        "        except ValueError as e:\n",
        "            print(f\"Skipping Epoch {epoch}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Calculate FID and KID for the current epoch\n",
        "        fid, kid = calculate_fid_kid(real_images, generated_images)\n",
        "\n",
        "        # Append the results to the DataFrame\n",
        "        new_row = {'Epoch': epoch, 'FID': fid, 'KID': kid}\n",
        "        df = df.append(new_row, ignore_index=True)\n",
        "\n",
        "        print(f\"Epoch {epoch} - FID: {fid}, KID: {kid}\")\n",
        "\n",
        "    # Save the DataFrame to the CSV file\n",
        "    df.to_csv(excel_path, index=False)\n",
        "\n",
        "# Specify the paths for real images and generated images base folder\n",
        "real_folder = '/content/drive/MyDrive/ML_Pro1/testing/Loc/Loc'\n",
        "generated_base_folder = '/content/drive/MyDrive/ML_Pro1/Loc_data'\n",
        "\n",
        "# Specify the range of epochs to calculate\n",
        "epochs_to_calculate = range(50, 501, 50)  # Adjust as needed\n",
        "\n",
        "calculate_fid_kid_for_epochs(real_folder, generated_base_folder, epochs_to_calculate)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1NDaE8qiVb7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSNR"
      ],
      "metadata": {
        "id": "bMIqzbZqFzeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "def calculate_psnr(img1, img2, max_value=255):\n",
        "    mse = torch.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * torch.log10(max_value / torch.sqrt(mse))\n",
        "\n",
        "\n",
        "df_psnr = pd.DataFrame(columns=['Epoch', 'Average PSNR'])\n",
        "\n",
        "avg_psnr = []\n",
        "epochs = []\n",
        "\n",
        "def psnr_fn(epoch_number):\n",
        "  # Define the paths to the generated and real image folders\n",
        "  fake_image_folder = \"/content/drive/MyDrive/ML_Pro1/Loc_data/Loc_\"+str(epoch_number)+\"Epoch_Images\"\n",
        "  real_image_folder = '/content/drive/MyDrive/ML_Pro1/testing/Loc/Loc'\n",
        "\n",
        "  psnr_values = []\n",
        "\n",
        "\n",
        "\n",
        "  fake_image_files = [f for f in os.listdir(fake_image_folder) if f.endswith('.png')]\n",
        "  real_image_files = [f for f in os.listdir(real_image_folder) if f.endswith('.png')]\n",
        "\n",
        "  for fake_image_file in fake_image_files:\n",
        "      for real_image_file in real_image_files:\n",
        "          fake_image_path = os.path.join(fake_image_folder, fake_image_file)\n",
        "          real_image_path = os.path.join(real_image_folder, real_image_file)\n",
        "\n",
        "          # Load images using PIL and convert to PyTorch tensors\n",
        "          fake_image = torch.tensor(np.array(Image.open(fake_image_path))).float() / 255.0\n",
        "          real_image = torch.tensor(np.array(Image.open(real_image_path))).float() / 255.0\n",
        "\n",
        "          # Resize images if needed\n",
        "          fake_image = torch.nn.functional.interpolate(fake_image.unsqueeze(0), size=(128, 128)).squeeze()\n",
        "          real_image = torch.nn.functional.interpolate(real_image.unsqueeze(0), size=(128, 128)).squeeze()\n",
        "\n",
        "          # Calculate PSNR for each color channel\n",
        "          psnr_channel = []\n",
        "          for channel in range(3):  # Assuming RGB images\n",
        "              psnr_value = calculate_psnr(fake_image[channel], real_image[channel], max_value=1.0)\n",
        "              psnr_channel.append(psnr_value.item())\n",
        "\n",
        "          # Take the average PSNR across color channels\n",
        "          average_psnr_channel = sum(psnr_channel) / len(psnr_channel)\n",
        "          psnr_values.append(average_psnr_channel)\n",
        "\n",
        "\n",
        "\n",
        "  # Calculate the overall average PSNR\n",
        "  average_psnr = sum(psnr_values) / len(psnr_values)\n",
        "\n",
        "  print(f\"Avg PSNR at epoch {epoch_number}: {average_psnr:.2f}\")\n",
        "\n",
        "\n",
        "  # Append epochs and avg psnr\n",
        "  epochs.append(epoch_number)\n",
        "  avg_psnr.append(average_psnr)\n",
        "\n",
        "\n",
        "#calling fn over all the epochs\n",
        "for epoch in [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]:\n",
        "  psnr_fn(epoch)\n",
        "\n",
        "\n",
        "# Specify the file name\n",
        "file_name = '/content/drive/MyDrive/ML_Pro1/output_psnr_Loc.csv'\n",
        "\n",
        "# Combine the lists into a list of tuples\n",
        "data = list(zip(epochs, avg_psnr))\n",
        "\n",
        "# Write the data to a CSV file\n",
        "with open(file_name, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "\n",
        "    # Write the header\n",
        "    csv_writer.writerow(['Epochs', 'Average PSNR'])\n",
        "\n",
        "    # Write the data\n",
        "    csv_writer.writerows(data)\n",
        "\n",
        "print(f'Data has been saved to {file_name}')"
      ],
      "metadata": {
        "id": "4-O0FFxN2eYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inception"
      ],
      "metadata": {
        "id": "m1M-G1Fdhpna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.models import inception_v3\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Define the Inception model\n",
        "class InceptionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InceptionModel, self).__init__()\n",
        "        self.inception_model = inception_v3(pretrained=True, transform_input=False)\n",
        "        self.inception_model.eval()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.inception_model(x)[0]\n",
        "\n",
        "# Define the function to calculate the Inception Score\n",
        "def calculate_inception_score(images, batch_size=32, resize=True):\n",
        "    # Set up the Inception model\n",
        "    inception_model = InceptionModel()\n",
        "\n",
        "    # Check if there are subdirectories\n",
        "    subdirectories = [f for f in os.listdir(images) if os.path.isdir(os.path.join(images, f))]\n",
        "\n",
        "    if subdirectories:\n",
        "        # Use ImageFolder approach if subdirectories are present\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((299, 299)) if resize else transforms.ToTensor(),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        dataset = ImageFolder(root=images, transform=transform)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "        # Compute activations for the generated images\n",
        "        all_activations = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                batch = batch[0]\n",
        "                activations = inception_model(batch)\n",
        "                all_activations.append(activations.cpu().numpy())\n",
        "\n",
        "        all_activations = np.concatenate(all_activations, axis=0)\n",
        "    else:\n",
        "        # Direct loading approach if no subdirectories\n",
        "        # Get the list of image file paths\n",
        "        image_files = [os.path.join(images, img) for img in os.listdir(images) if img.endswith(('.png', '.jpg', '.jpeg', '.gif'))]\n",
        "\n",
        "        # Set up data loader for generated images\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((299, 299)) if resize else transforms.ToTensor(),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        # Load images\n",
        "        all_images = []\n",
        "        for img_path in image_files:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            img_tensor = transform(img)\n",
        "            all_images.append(img_tensor)\n",
        "\n",
        "        if not all_images:\n",
        "            raise ValueError(\"No images found in the specified directory.\")\n",
        "\n",
        "        all_activations = torch.stack(all_images)\n",
        "\n",
        "    # Compute the Inception Score\n",
        "    scores = []\n",
        "    split_size = 10\n",
        "    all_activations_tensor = torch.tensor(all_activations)\n",
        "    split_activations = torch.split(all_activations_tensor, len(all_activations_tensor) // split_size)\n",
        "\n",
        "    for activations in split_activations:\n",
        "        activations = activations.view(-1, activations.shape[-1])\n",
        "        scores.append(F.softmax(activations, dim=1))\n",
        "\n",
        "    scores = torch.cat(scores, dim=0)\n",
        "    kl_divergence = scores * (torch.log(scores) - torch.log(torch.mean(scores, dim=0)))\n",
        "    final_score = torch.exp(torch.mean(torch.sum(kl_divergence, dim=1)))\n",
        "\n",
        "    return final_score.item()\n",
        "\n",
        "# Path to the folder containing generated images for different epochs\n",
        "generated_images_base_folder = \"/content/drive/MyDrive/ML_Pro1/Loc_data\"\n",
        "\n",
        "# CSV file to store Inception Scores\n",
        "csv_file_path = 'inception_scores_Loc.csv'\n",
        "\n",
        "# Create an empty DataFrame to store results\n",
        "df_combined = pd.DataFrame(columns=['Epoch', 'Inception_Score'])\n",
        "\n",
        "# Iterate over each subfolder corresponding to different epochs\n",
        "for epoch_folder in sorted(os.listdir(generated_images_base_folder), key=lambda x: int(re.search(r'(\\d+)', x).group(0)) if re.search(r'(\\d+)', x) else float('inf')):\n",
        "    epoch_folder_path = os.path.join(generated_images_base_folder, epoch_folder)\n",
        "\n",
        "    # Check if it is a directory\n",
        "    if os.path.isdir(epoch_folder_path):\n",
        "        try:\n",
        "            # Calculate Inception Score for each epoch\n",
        "            inception_score = calculate_inception_score(epoch_folder_path)\n",
        "\n",
        "            # Append the new Inception Score to the DataFrame\n",
        "            df_combined = pd.concat([df_combined, pd.DataFrame({'Epoch': [epoch_folder], 'Inception_Score': [inception_score]})], ignore_index=True)\n",
        "\n",
        "        except ValueError as e:\n",
        "            print(f\"Skipping {epoch_folder}: {e}\")\n",
        "\n",
        "# Save to CSV\n",
        "df_combined.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(\"Inception Scores calculation completed and saved to CSV.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fUILflzojiva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wqt7mLGCvSh7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}